\chapter{实验与评估}
本章主要介绍了针对本文提出模型所设计的实验以及结果分析。与上文各章节对应，实验分为了三块，分别对应事件因果关系发掘、组件-事件知识图谱表示学习、故障预测三部分工作。
\begin{table}[htbp]
    \caption{集群各类组件数量统计}
    \label{component-num}
    \centering
    \begin{tabular}{lll}
    \hline
    组件名称      & train-ticket & sock-shop        \\ \hline
    vpc       & 34           & \textbackslash{} \\
    slb       & 30           & \textbackslash{} \\
    ecs       & 30           & \textbackslash{} \\
    pod       & 215          & \textbackslash{} \\
    container & 720          & \textbackslash{} \\
    service   & 172          & \textbackslash{} \\ \hline
    \end{tabular}
\end{table}

\begin{table}[htbp]
    \caption{故障模拟信息}
    \centering
    \label{failure-simulation-info}
    \begin{tabular}{lll}
    \hline
               & train-ticket & \multicolumn{1}{c}{sock-shop} \\ \hline
    时间跨度       & 25天          & 14天                           \\
    平均故障时间段跨度  & 303s         & 310s                          \\
    单位故障含有事件数目 & 4823         & 3352                          \\
    故障次数       & 423          & 550                           \\
    故障种类       & 10           & 17                            \\
    事件类型种类     & 204          & 211                           \\ \hline
    \end{tabular}
\end{table}

实验采用了阿里云kubernetes集群，集群各个组件数量如表\ref{component-num}所示。在该集群上部署了文献\parencite{}中使用的两个分布式应用，即\href{https://github.com/FudanSELab/train-ticket}{train-ticket}和\href{https://github.com/microservices-demo/microservices-demo}{sock-shop}。随后使用kube-monkey和chaosblade模拟故障，在异常注入到故障产生的时间段中，阿里云的sls平台负责收集实时产生的日志数据和指标时序数据。所模拟故障的数据统计信息如表\ref{failure-simulation-info}所示。其中所有的数据后续经过事件生成模块，均转化为了事件类型数据。

事件类型数据按照来源划分可以分成两类：指标时序事件和日志事件。指标时序事件对应着曲线变化的异常点，而日志事件对应着集群中组件实时产生的日志。指标时序事件和日志事件可以继续往下划分，划分类别和每类别数目如下表\ref{event-type-level}所示。
\begin{table}[htbp]
    \caption{事件类型层次关系}
    \label{event-type-level}
    \begin{tabular}{llll}
    \hline
    事件大类别    & 细分           & 类别数目（train-ticket） & 类别数目（sock-shop） \\ \hline
    metric事件 & 异常点事件        & 64                 & 64              \\
             & 告警事件         & 21                 & 21              \\ \hline
    log事件    & k8s日志事件      & 50                 & 50              \\
             & dockerIO日志事件 & 69                 & 76              \\ \hline
    共计       &              & 204                & 211             \\ \hline
    \end{tabular}
    \end{table}

异常点事件由监控项合并异常点类型构成，表示了在设备的某个监控项曲线出现了某种异常点。监控项共有16种，如式\ref{kpi-event}所示。异常点类型共有4种：突然上升、突然下降、尖峰、低估。每个监控项都会出现这四种异常点，比如$system.cpu.util$突然上升$system.cpu.util$突然下降、$system.cpu.util$出现尖峰、$system.cpu.util$出现低估。因此，将每个监控项与异常点类型组合，可生成共计64种异常点事件。
\begin{equation}
    \begin{array}{l}
        container.cpu.load.average.10s,\\
        container.cpu.usage.seconds.total,\\
        container.fs.reads.bytes.total,\\
        container.fs.writes.bytes.total,\\
        container.memory.usage.bytes,\\
        container.network.receive.bytes.total,\\
        container.network.receive.packets.dropped.total,\\
        container.network.transmit.bytes.total,\\
        container.network.transmit.packets.dropped.total,\\
        system.net.drop.util,\\
        system.net.in,\\
        system.net.out,\\
        system.io.disk_rbps,\\
        system.io.disk_wbps,\\
        system.mem.util,\\
        system.cpu.util\\ 
    \end{array}
    \label{kpi-event}
\end{equation}

告警事件是由监控项组合阈值构成的，表明了在设备的某个监控项上出现了达到阈值的告警信息。监控项共7种，每个监控项目都有3种告警阈值。监控项和对应阈值如表\ref{alarm-event}。每个监控项都会生成3种告警事件，比如$system.cpu.util$大于$100\%$、$system.cpu.util$大于$90\%$、$system.cpu.util$大于$95\%$。因此，将每个监控项与异常点类型组合，可生成告警事件共计21种。
\begin{table}[]
    \centering
    \caption{告警事件监控项及阈值}
    \label{alarm-event}
    \begin{tabular}{ll}
    \hline
    监控项                          & 阈值              \\ \hline
    pod.cpu.util                 & 100\% 95\% 90\% \\
    pod.mem.util                 & 100\% 95\% 90\% \\
    system.cpu.util              & 100\% 95\% 90\% \\
    system.mem.util              & 100\% 95\% 90\% \\
    system.net.drop.util         & 20\% 10\% 5\%   \\
    system.net.err.util          & 20\% 10\% 5\%   \\
    system.partition.space.usage & 100\% 95\% 90\% \\ \hline
    \end{tabular}
    \end{table}

k8s（kubeneters）是分布式集群容器的管理系统，k8s日志事件就是k8s管理系统产生的事件，包含pod镜像拉取、pod健康状况等事件。这类事件共有50种细分类型，式\ref{k8s-event}展示了部分k8s日志事件类型。
\begin{equation}
    \begin{array}{l}
        Unhealthy.Warning, \\
        Killing.Normal,\\
        Scheduled.Normal,\\
        Pulled.Normal,\\
        Created.Normal,\\
        Started.Normal,\\
        Pulling.Normal,\\
        BackOff.Warning,\\
        FailedSync.Warning,\\
        Failed.Warning,\\
        FailedCreatePodSandBox.Warning,\\
        SandboxChanged.Normal,\\
        FailedKillPod.Warning,\\
        FailedScheduling.Warning,\\
        BackOff.Normal,\\
        FailedMount.Warning,\\ 
        Scheduled.Normal,\\
        Pulled.Normal,\\
    \end{array}
    \label{k8s-event}
\end{equation}

DockerIO日志事件指的是Docker中的输入输出日志所转化生成的事件。该类事件记录了Docker\cite{boettiger2015introduction}中的各种操作信息和容器中微服务应用运行时日志。在将这些日志聚类并编写人工模板后，人工模板被用来匹配日志信息以收集统计DockerIO日志事件类型。其中，由于不同分布式应用的微服务结构不同，且输出日志直接由开发人员编写的日志打印代码所决定，所以在两应用中得到的事件类型有所不同。最终train-ticket应用中收集到69种DockerIO日志事件，而sock-shop应用中共收集到76种DockerIO日志事件。式\ref{dockerio-event}中列出了其中部分DockerIO日志事件类型名称。
\begin{equation}
    \begin{array}{l}
        java.lang.AbstractMethodError,\\
        java.lang.AssertionError,\\
        java.lang.ClassCircularityError,\\
        java.lang.ClassFormatError,\\
        java.lang.Error,\\
        spring.server.connect.failed,\\
        warn.Omitting,\\
        warning.stderr,\\
        spring.http.server.error,\\
        error.mcp.Failed.to.create.a.new.MCP.sink.stream,\\
        trying.to.establish.new.MCP.sink.stream,\\
        socket.go.Successful.write.metrics.to.monitor.server,\\
        operator.go.sync.prometheus,\\
        event.go.reason.UPDATE.Ingress,\\
    \end{array}
    \label{dockerio-event}
\end{equation}

\section{事件因果关系判别实验}
\textbf{数据集构建}：本实验对数据集中的关系种类进行了标注，标注数据覆盖了每一种故障类型，其中对每种故障类型，随机抽取了两个具体时间段场景进行了标注，只对认为有关系的事件对标注为+1，其余事件对默认无关系即为-1。最终标注为+1的共计286条，其余默认无关系的共计8,250,290‬条。数据集train-ticket、sock-shop的标注信息如下表\ref{event-cause-label}。由于正负样本数量级差距较大，后续选择了按照正样本：负样本为1：10的比例随机抽取了一批数据用于训练。抽取出作为训练的数据包含正样本286条，负样本2860条。
\begin{table}[htbp]
    \caption{事件对因果关系标注数据集}
    \centering
    \label{event-cause-label}
    \begin{tabular}{llll}
    \hline
                 & 正例  & 负例      & 总计      \\ \hline
    train-ticket & 121 & 3610827 & 3610948 \\
    sock-shop    & 165 & 4639463 & 4639628 \\ \hline
    总计           & 286 & 8250290 & 8250576 \\ \hline
    \end{tabular}
    \end{table}

\textbf{评测标准}：由于事件因果关系判别模型目的在于正确判别事件对之间的关系，所以本块实验以被标注的事件对关系被识别的精确率（Precision）、召回率（Recall）和F1值作为评测标准。计算公式如式\ref{relation-classifier-prf}所示。
\begin{equation}
    \begin{array}{c}
    \text { precision }=\frac{\left|R_{\text {correct }}\right|}{|R|} \\
    \text { recall }=\frac{\left|R_{\text {correct }}\right|}{\left|R_{\text {label }}\right|} \mid \\
    F 1=\frac{2 * \text { precision } * \text { recall }}{\text { precision }+\text { recall }}
    \end{array}
    \label{relation-classifier-prf}
\end{equation}

其中$precision$、$recall$、$F1$分别代表精确率、召回率和F1值。$\left|R_{\text {correct }}\right|$为同时被标注存在因果关系且被判别为存在因果关系的事件对数，$|R|$为模型判别为有因果关系的事件对数，$\left|R_{\text {label }}\right|$为被标注存在因果关系的事件对数。(todo：各个模型所使用的超参数)

\textbf{实验方法}：对用于训练数据中正样本286条、负样本2860条，随机抽取平分为5份，以便采用5折交叉验证方法。其中每份正样本数57，负样本数572。实验中选用了SVM、XGBoost、随机森林、逻辑回归和多层感知机共计五种模型进行了对比实验。

\textbf{实验结果}：实验统计了各个模型在进行5折交叉验证时，所计算得到的精确率、召回率和F1值，结果统计如表\ref{cause-relation-result}所示。从中可以看到SVM模型的精确率、召回率和F1值均达到了0.95以上，而随机森林、逻辑回归和Xgboost效果较差，原因在于这三者受数据不平衡影响较大。另外，多层感知机召回率达到了1.0，而精确率值有0.89，可见其偏向于将数据都判别为正例，会做出过多的假阳判断。
\begin{table}[]
    \caption{各分类模型事件因果关系判别结果}
    \centering
    \label{cause-relation-result}
    \begin{tabular}{llll}
    \hline
    模型      & 精确率            & 召回率          & F1             \\ \hline
    SVM     & \textbf{0.951} & 0.961        & \textbf{0.956} \\
    Xgboost & 0.911          & 0.895        & 0.903          \\
    随机森林    & 0.950          & 0.792        & 0.864          \\
    逻辑回归    & 0.913          & 0.845        & 0.878          \\
    多层感知机   & 0.892          & \textbf{1.0} & 0.943          \\ \hline
    \end{tabular}
\end{table}

\section{组件-事件知识图谱表示学习实验}
\textbf{数据集构建}：事件因果关系判别实验结束后，历史数据会按照故障类型分组，本文使用SVM从每类故障对应的历史数据中挖掘事件因果对，再按照章节\ref{graph-generate}所示步骤沉淀生成每类故障的组件-事件知识图谱。表\ref{kg-abstract-event-num}统计了两个分布式应用每类故障类型所对应组件-事件知识图谱的抽象事件实体数目及因果关系对数。随后的实验中，数据的输入形式为四元组$(graph,head,relation,tail)$，即输入三元组$(head,relation,tail)$及其所在上下文图结构$graph$。（todo:训练测试三元组数据）
\begin{table}[htbp]
    \caption{各类故障对应知识图谱信息}
    \label{kg-abstract-event-num}
    \begin{tabular}{ccccc}
    \hline
    数据集          & 故障代号                                                      & 知识库节点数目 & 知识库关系数目 & （结点：关系） \\ \hline
    train-ticket & f1                                                        & 41      & 285     & 4：5     \\
                 & f2                                                        & 39      & 297     & 10：13   \\
                 & f3                                                        & 6       & 8       & 8：8     \\
                 & f5                                                        & 62      & 81      & 3：2     \\
                 & f6                                                        & 34      & 233     & 5：5     \\
                 & f10                                                       & 15      & 51      & 8：6     \\
                 & f13                                                       & 15      & 15      & 4：2     \\
                 & f16                                                       & 35      & 59      & 8：1     \\
                 & f17                                                       & 38      & 65      & 6：2     \\
                 & f18                                                       & 54      & 88      & 5：1     \\ \hline
    sock-shop    & db\_goods\_disappeared           & 20      & 86      & 5：10    \\
                 & db\_cart\_disappeared                      & 70      & 638     & 4：6     \\
                 & user\_unable\_log\_in                        & 52      & 180     & 4：6     \\
                 & db\_order\_disappeared                   & 20      & 114     & 7：16    \\
                 & order\_cart\_500                                          & 9       & 8       & 4：4     \\
                 & order\_count\_500                                         & 55      & 536     & 9：18    \\
                 & order\_payment\_500                                       & 13      & 30      & 3：3     \\
                 & user\_register\_500                                 & 7       & 6       & 3：3     \\
                 & cart\_disappeared                             & 4       & 5       & 2：1     \\
                 & catalogue\_goods\_disappeared              & 6       & 7       & 3：3     \\
                 & add\_cart\_delay              & 30      & 57      & 2：1     \\
                 & user\_register\_and\_log\_in\_delay & 17      & 43      & 2：1     \\
                 & check\_order\_delay         & 102     & 598     & 4：3     \\
                 & net\_loss\_check\_order          & 92      & 614     & 4：3     \\
                 & net\_loss\_add\_cart               & 34      & 79      & 3：3     \\
                 & net\_loss\_user\_register\_and\_log\_in  & 17      & 55      & 2：1     \\
                 & net\_loss\_goods\_appear\_delay & 15      & 33      & 2：1     \\ \hline
    \end{tabular}
    \end{table}


\textbf{评测标准}：在组件-事件知识图谱表示学习模型评测方式中有两个被广泛使用的任务。

任务1：链接预测，即预测三元组中丢失的头实体或尾实体。文献\parencite{bordes2011learning,bordes2013translating}定义链接预测为给定$(head,relation)$或$(relation,tail)$预测对应丢失的$tail$或$head$。在具体进行链接预测任务时，实验会排序候选实体集合，而不是直接给出最佳匹配实体。依据文献\parencite{bordes2013translating}的做法，对于每一个测试三元组$(head,relation,tail)$，实验中会使用知识图谱中任意不匹配$(relation,tail)$的实体来替换$head$，然后根据模型输出的匹配概率分数降序排列这些三元组。同样的，也可以重复上述过程来替换尾实体$tail$。在收集完所有三元组后，本文使用了两个衡量指标：正确实体的平均排名（即Mean Rank）；正确实体在前N名的占比（即Hits@N）。平均排名越小或Hits@N越大，都意味着表示模型效果越好。

任务2：三元组分类，即判断给定的三元组是否是知识图谱中真实存在的。在三元组分类任务中，给定知识图谱$graph$和三元组$(head,relation,tail)$，需要判断它是否是正确的。该任务已经在已有的工作\parencite{bordes2013translating,wang2014knowledge,lin2015learning}中展开过，也被广泛的应用在很多自然语言处理场景，比如问答。

% 我们首先对标准链路预测任务中的不同嵌入模型进行了比较研究，即预测不可见三胞胎的正确性。如（Bordes et al.，2013b）中所述，我们将链接预测作为实体排序任务。对于测试数据中的每个三元组，我们依次将每个实体作为要预测的目标实体。计算字典中正确实体和所有损坏实体的分数，并按降序排列。我们考虑平均倒数秩（MRR）（一个回答实体的倒数秩在所有测试三元组上的平均值），命中@10（前10名精度）和平均精度（MAP）（如（Chang等人，2014年）中所用）作为评估指标（from EMBEDDING ENTITIES AND RELATIONS FOR LEARN-
% ING AND INFERENCE IN KNOWLEDGE BASES
% ）
\textbf{实验方法}：链接预测时，输入候选实体和上下文信息，输出三元组损失值，损失值越大排名越低，再计算对应的MRR和Hits@N即可。三元组分类时，输入待测三元组及其上下文，输出该三元组是否成立，再计算准确率、精确率、召回率和F1值即可。

\textbf{实验结果}：


\section{基于知识图谱与实时事件序列的故障预测实验}
\textbf{数据集构建}：在构建组件-事件知识图谱时，已经使用了一半的故障时间段数据，本处的故障预测实验选择使用剩下一半的故障时间段数据。由于每一个故障时间段都有对应的故障类型，所以此处不需要人工标注，直接将同一故障类型的知识图谱与事件序列视为相似，不同故障类型的知识图谱与事件序列视为不相似。

由于故障预测任务是根据已发生的事件序列，预测可能会出现何种故障，所以对每一个实例时间段的事件序列选择去除其最后的故障事件，只保留故障发生前的异常事件序列。此外，每个时间段的事件序列长度不一致，而双向记忆网络模型的输入长度需要是确定的。所以，若记忆网路的输入长度为L，对于长度小于L的事件序列直接保留，对于长度长于L的事件序列进行随机采样N次生成N个新的长度为L事件序列。这样随机采样生成新事件序列的方式，使得模型具有了鲁棒性，即使面对完整事件序列的部分信息，也可以正确预测其可能发生的故障。

最终获取到两数据集实时事件序列数目如表\ref{event-sequence-num}所示，并按照6:4划分了训练集和测试集。
\begin{table}[htbp]
    \centering
    \caption{实时事件序列数}
    \label{event-sequence-num}
    \begin{tabular}{ccccc}
        \hline
        数据集名称        & 初始事件序列数 & 随机采样后事件序列数 & 训练集 & 测试集 \\ \hline
        Train-ticket & 235     & 532     & 323 & 209 \\
        Sock-shop    & 214     & 595     & 363 & 232 \\ \hline
    \end{tabular}
\end{table}

\textbf{评测标准}：最终的评测标准以测试集中事件序列分类到组件-事件知识图谱的精确率、召回率和F1值为准。

\textbf{实验方法}：在模型训练过程中，每一个事件序列除了有其对应的相似组件-事件知识图谱$G_{pos}$，还需负采样任选一个不相似的组件-事件知识图谱$G_{neg}$。模型训练目标函数为最大化两者差距，即与相似组件-事件知识图谱的相似度$Sim_{pos}$要远大于与不相似的组件-事件知识图谱的相似度$Sim_{pos}$。在计算测量指标时，首先将事件序列与组件-事件知识图谱中每个图谱都做相似度计算，并按照相似度降序排列，将对应组件-事件知识图谱排序第一时视作正确的。(todo-超参数 对比实验)

\textbf{实验结果}：实验中分别记录训练集和测试集的准确率、精确率、召回率和F1值，结果如表\ref{experiment-predict-train-test}所示，可见在两个数据集上模型的表现具有差别，主要原因在于
\begin{table}[htbp]
    \caption{模型训练和测试集效果}
    \centering
    \label{experiment-predict-train-test}
    \begin{tabular}{lllllll}
    \hline
    数据集名称        & 划分数据集 & LOSS & Accuary & F1     & Pecision & Recall \\ \hline
    Train-ticket & 训练集   & 2907 & 1       & 1      & 1        & 1      \\
                 & 测试集   & 360  & 0.9234  & 0.9175 & 0.9385   & 0.9037 \\ \hline
    Sock-shop    & 训练集   & 6284 & 1       & 0.9412 & 1        & 1      \\
                 & 测试集   & 683  & 0.875   & 0.8612 & 0.887    & 0.8475 \\ \hline
    \end{tabular}
    \end{table}
\section{本章小结}
本章主要介绍了针对前面各章所述模型的实验实施。在事件因果关系挖掘模块，实验对比了多种机器学习模型，并对比了只依据概率特征和依据本文6种特征的表现，最终取F1值最高的SVM作为最终的因果判别模型；在组件-事件知识图谱表示学习模块，实验对比了已有工作中的模型和本文提出模型，实验效果表明本文引入图传播模型作为编码器生成事件动态嵌入表示的方法在链接预测和三元组分类任务上都取得了最佳效果；在故障预测部分，实验对比了相关工作的模型和本文模型，实验效果表明在本文表示学习模型基础上再引入知识图谱会取得最佳的预测效果。下一章将介绍基于本文已提出模型所设计的IT运维辅助系统。




